{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7272892,"sourceType":"datasetVersion","datasetId":4216282},{"sourceId":9934551,"sourceType":"datasetVersion","datasetId":6107281}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch \nfrom torch import nn\nimport os\nimport torchvision\nimport torch.nn.functional as F\nfrom torch import tensor\nfrom torch.utils.data import DataLoader\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nfrom tqdm import tqdm\nfrom matplotlib import pyplot as plt\nimport json","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T18:37:49.505927Z","iopub.execute_input":"2024-11-17T18:37:49.506299Z","iopub.status.idle":"2024-11-17T18:37:49.512479Z","shell.execute_reply.started":"2024-11-17T18:37:49.506263Z","shell.execute_reply":"2024-11-17T18:37:49.511407Z"}},"outputs":[],"execution_count":434},{"cell_type":"code","source":"class CustomCNN(nn.Module):\n    \n    def __init__(self, num_classes):\n        \n        super(CustomCNN, self).__init__()\n        self.num_classes = num_classes\n        self.conv1 = nn.Conv2d(3, 3, kernel_size=3, padding=1)\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        # self.batch_norm1 = nn.BatchNorm2d(3)\n\n        self.conv3 = nn.Conv2d(3, 3, kernel_size=3, padding=1)\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        # self.batch_norm2 = nn.BatchNorm2d(3)\n\n        self.conv5 = nn.Conv2d(3, 3, kernel_size=3, padding=1)\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n        # self.batch_norm3 = nn.BatchNorm2d(3)\n\n        self.conv8 = nn.Conv2d(3, 3, kernel_size=3, padding=1)\n        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=1)  # default stride is 2\n        # self.batch_norm4 = nn.BatchNorm2d(3)\n\n        self.conv11 = nn.Conv2d(3, 3, kernel_size=3, padding=1)\n        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=1)  # default stride is 2\n        self.batch_norm5 = nn.BatchNorm2d(3)\n\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Linear(3, num_classes)\n        \n    def forward(self, x):\n        \n        x1 = F.leaky_relu(self.conv1(x))\n        x1 = self.pool1(x1)\n        # x1 = self.batch_norm1(x1)\n        \n        x2 = F.leaky_relu(self.conv3(x1))\n        x2 = self.pool2(x2)\n        # x2 = self.batch_norm2(x2)\n\n        x3 = F.leaky_relu(self.conv5(x2))\n        x3 = self.pool3(x3)\n        # x3 = self.batch_norm3(x3)\n\n        x4 = F.leaky_relu(self.conv8(x3))\n        x4 = self.pool4(x4)\n        # x4 = self.batch_norm4(x4)\n\n        x5 = F.leaky_relu(self.conv11(x4))\n        x5 = self.pool5(x5)\n        x5 = self.batch_norm5(x5)\n        \n        y = self.flatten(x5)\n        y = F.leaky_relu(self.fc1(y))\n        return x1, x2, x3, x4, x5, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T18:50:32.098325Z","iopub.execute_input":"2024-11-17T18:50:32.099066Z","iopub.status.idle":"2024-11-17T18:50:32.111322Z","shell.execute_reply.started":"2024-11-17T18:50:32.099024Z","shell.execute_reply":"2024-11-17T18:50:32.110332Z"}},"outputs":[],"execution_count":527},{"cell_type":"code","source":"class CustomCNN_sieve(nn.Module):\n\n    def __init__(self, shape1, shape2, shape3, shape4, shape5, num_classes):\n\n        super().__init__()\n        self.num_classes = num_classes\n        self.core_network = CustomCNN(self.num_classes)\n        \n        self.shape1 = shape1\n        self.shape2 = shape2\n        self.shape3 = shape3\n        self.shape4 = shape4\n        self.shape5 = shape5\n        \n        self.sieve1 = nn.Linear(self.shape1[0] * self.shape1[1] * self.shape1[2], self.num_classes)\n        self.sieve2 = nn.Linear(self.shape2[0] * self.shape2[1] * self.shape2[2], self.num_classes)\n        self.sieve3 = nn.Linear(self.shape3[0] * self.shape3[1] * self.shape3[2], self.num_classes)\n        self.sieve4 = nn.Linear(self.shape4[0] * self.shape4[1] * self.shape4[2], self.num_classes)\n        self.sieve5 = nn.Linear(self.shape5[0] * self.shape5[1] * self.shape5[2], self.num_classes)\n        self.flatten = nn.Flatten(start_dim = 1, end_dim = 3)\n\n    def forward(self, x):\n\n        s1, s2, s3, s4, s5, main_output = self.core_network(x)\n        return self.sieve1(self.flatten(s1)), self.sieve2(self.flatten(s2)), self.sieve3(self.flatten(s3)), self.sieve4(self.flatten(s4)), self.sieve5(self.flatten(s5)), main_output\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T18:50:32.283253Z","iopub.execute_input":"2024-11-17T18:50:32.284140Z","iopub.status.idle":"2024-11-17T18:50:32.294225Z","shell.execute_reply.started":"2024-11-17T18:50:32.284089Z","shell.execute_reply":"2024-11-17T18:50:32.293313Z"}},"outputs":[],"execution_count":528},{"cell_type":"code","source":"def training(model, dataloader, optimizer_core, optimizer_sieve, num_classes, lamb, epochs = 10):\n\n    for epoch in tqdm(range(epochs)):\n\n        epoch_loss_main = 0 \n        epoch_loss_sieve = 0 \n        iters = 0 \n        \n        for iter, (image, label) in enumerate(dataloader): \n\n            optimizer_core.zero_grad()\n            optimizer_sieve.zero_grad()\n            \n            image, label = image.to(device), label.to(device)\n            model.train()\n            \n            _, _, _, _, _, main_output = model(image)\n            main_loss = F.binary_cross_entropy_with_logits(main_output, label)\n            epoch_loss_main += main_loss.item()\n            iters += 1\n            \n            main_loss.backward()\n\n            # if(iter%30 == 0):\n            #     for name, param in model_sieve.named_parameters():\n            #         if param.grad is None:\n            #             print(f\"Layer {name} has no gradients.\")\n            #         else:\n            #             print(f\"Layer {name} gradient mean: {param.grad.mean()}\")\n\n            #     print('\\n')\n                        \n            optimizer_core.step()\n            model.core_network.eval()\n\n            s1, s2, s3, s4, s5, _ = model(image)\n            loss1 = F.cross_entropy(s1, label)\n            loss2 = F.cross_entropy(s2, label)\n            loss3 = F.cross_entropy(s3, label)\n            loss4 = F.cross_entropy(s4, label)\n            loss5 = F.cross_entropy(s5, label)\n\n            loss = loss1 + loss2 + loss3 + loss4 + loss5\n            epoch_loss_sieve += loss.item()\n            # optimizer_model.zero_grad()\n            # optimizer_weights.zero_grad()\n            loss.backward()\n\n            # if(iter%20 == 0):\n            #     for name, param in model_sieve.named_parameters():\n            #         if param.grad is None:\n            #             print(f\"Layer {name} has no gradients.\")\n            #         else:\n            #             print(f\"Layer {name} gradient mean: {param.grad.mean()}\")\n\n            #     print('\\n')\n                \n            optimizer_sieve.step()\n            # optimizer_weights.step()\n            image,label = image.to('cpu'), label.to('cpu')\n            \n            \n        print(f'The epoch is {epoch + 1}, the main loss is {epoch_loss_main/iters} and the sieve loss is {epoch_loss_sieve/iters}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T18:50:32.462248Z","iopub.execute_input":"2024-11-17T18:50:32.463036Z","iopub.status.idle":"2024-11-17T18:50:32.473814Z","shell.execute_reply.started":"2024-11-17T18:50:32.462998Z","shell.execute_reply":"2024-11-17T18:50:32.472832Z"}},"outputs":[],"execution_count":529},{"cell_type":"code","source":"def forgetting(model, weights, dataloader, optimizer_core, num_classes, lamb, epochs = 10):\n\n    for epoch in range(epochs):\n        \n        iters = 0 \n        total_loss1 = 0\n        total_loss2 = 0\n        total_loss3 = 0\n        total_loss4 = 0\n        total_loss5 = 0\n        \n        for image, _ in dataloader: \n\n            image = image.to(device)\n            label = torch.ones((image.shape[0] , num_classes), dtype = torch.float).to(device)\n            label = label/num_classes \n            iters+=1 \n            \n            model.eval()\n            s1, s2, s3, s4, s5, _ = model(image)\n            optimizer_core.zero_grad() \n            \n            model.sieve1.train()\n            model.core_network.conv1.train()\n            model.core_network.pool1.train()\n            # model.core_network.batch_norm1.train()\n            loss1 = weights[0]*F.binary_cross_entropy_with_logits(s1, label)\n            total_loss1 += loss1.item()\n            loss1.backward(retain_graph=True)\n            model.eval()\n\n            model.sieve2.train()\n            model.core_network.conv3.train()\n            model.core_network.pool2.train()\n            # model.core_network.batch_norm2.train()\n            loss2 = weights[1]*F.binary_cross_entropy_with_logits(s2, label)\n            total_loss2 += loss2.item()\n            loss2.backward(retain_graph=True)\n            model.eval()\n\n            model.sieve3.train()\n            model.core_network.conv5.train()\n            model.core_network.pool3.train()\n            # model.core_network.batch_norm3.train()\n            loss3 = weights[2]*F.binary_cross_entropy_with_logits(s3, label)\n            total_loss3 += loss3.item()\n            loss3.backward(retain_graph=True)\n            model.eval()\n\n            model.sieve4.train()\n            model.core_network.conv8.train()\n            model.core_network.pool4.train()\n            # model.core_network.batch_norm4.train()\n            loss4 = weights[3]*F.binary_cross_entropy_with_logits(s4, label)\n            total_loss4 += loss4.item()\n            loss4.backward(retain_graph=True)\n            model.eval()\n\n            model.sieve5.train()\n            model.core_network.conv11.train()\n            model.core_network.pool5.train()\n            model.core_network.batch_norm5.train()\n            loss5 = weights[4]*F.binary_cross_entropy_with_logits(s5, label)\n            total_loss5 += loss5.item()\n            loss5.backward(retain_graph=True)\n            model.eval()\n\n            optimizer_core.step()\n\n            image = image.to('cpu')\n            label = label.to('cpu')\n            # loss = -(loss1 + loss2 + loss3 + loss4 + loss5) + lamb*torch.abs((weights[0] + weights[1] + weights[2] + weights[3] + weights[4]) - 1)\n            # loss.backward()\n\n            # optimizer_weights.zero_grad()\n            # optimizer_weights.step()\n\n        print(f\"The epoch is {epoch}.\\n loss1 is {total_loss1/iters} \\n loss2 is {total_loss2/iters} \\n loss3 is {total_loss3/iters} \\n loss4 is {total_loss4/iters} \\n loss5 is {total_loss5/iters}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T18:50:32.655245Z","iopub.execute_input":"2024-11-17T18:50:32.655607Z","iopub.status.idle":"2024-11-17T18:50:32.671290Z","shell.execute_reply.started":"2024-11-17T18:50:32.655572Z","shell.execute_reply":"2024-11-17T18:50:32.670286Z"}},"outputs":[],"execution_count":530},{"cell_type":"markdown","source":"## Code to load cifarmnist dataset","metadata":{}},{"cell_type":"code","source":"labels_path = train_images_path + 'labels.json'\nwith open(labels_path, \"r\") as json_file:\n    data = json.load(json_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T19:00:26.699129Z","iopub.execute_input":"2024-11-17T19:00:26.699536Z","iopub.status.idle":"2024-11-17T19:00:26.715676Z","shell.execute_reply.started":"2024-11-17T19:00:26.699497Z","shell.execute_reply":"2024-11-17T19:00:26.714872Z"}},"outputs":[],"execution_count":614},{"cell_type":"code","source":"data['Datas/Cifar10_Mnist_Lite/combined_image_999.png']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T18:34:11.640294Z","iopub.execute_input":"2024-11-17T18:34:11.640659Z","iopub.status.idle":"2024-11-17T18:34:11.646878Z","shell.execute_reply.started":"2024-11-17T18:34:11.640623Z","shell.execute_reply":"2024-11-17T18:34:11.645961Z"}},"outputs":[{"execution_count":407,"output_type":"execute_result","data":{"text/plain":"{'cifar10_label': 6, 'mnist_label': 5}"},"metadata":{}}],"execution_count":407},{"cell_type":"code","source":"train_images_path = '/kaggle/input/cifar-10-mnist/Cifar10_Mnist_Lite/'\nstart_path = 'Datas/Cifar10_Mnist_Lite/'\ncifar_dataset = []\nfor image_file in os.listdir(train_images_path):\n    if image_file.endswith('.json'): continue\n    img = tensor(torchvision.io.read_image(train_images_path + image_file), dtype = torch.float)\n    label_cifar = data[start_path + image_file]['cifar10_label']\n    label_mnist = data[start_path + image_file]['mnist_label']\n    cifar_dataset.append((img,label_cifar,label_mnist))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T18:34:43.371648Z","iopub.execute_input":"2024-11-17T18:34:43.372272Z","iopub.status.idle":"2024-11-17T18:34:44.103442Z","shell.execute_reply.started":"2024-11-17T18:34:43.372232Z","shell.execute_reply":"2024-11-17T18:34:44.102360Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/523452694.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  img = tensor(torchvision.io.read_image(train_images_path + image_file), dtype = torch.float)\n","output_type":"stream"}],"execution_count":410},{"cell_type":"markdown","source":"## Code to load colormnist dataset","metadata":{}},{"cell_type":"code","source":"# green 0 and red 1 in training \n# red 0 and green 1 in testing","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T19:02:32.278039Z","iopub.execute_input":"2024-11-17T19:02:32.278895Z","iopub.status.idle":"2024-11-17T19:02:32.282589Z","shell.execute_reply.started":"2024-11-17T19:02:32.278851Z","shell.execute_reply":"2024-11-17T19:02:32.281623Z"}},"outputs":[],"execution_count":668},{"cell_type":"code","source":"train_0_path = '/kaggle/input/colored-mnist-dataset/colorized-MNIST-master/training/0/'\ntrain_1_path = '/kaggle/input/colored-mnist-dataset/colorized-MNIST-master/training/1/'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T19:02:32.450647Z","iopub.execute_input":"2024-11-17T19:02:32.451501Z","iopub.status.idle":"2024-11-17T19:02:32.455654Z","shell.execute_reply.started":"2024-11-17T19:02:32.451456Z","shell.execute_reply":"2024-11-17T19:02:32.454723Z"}},"outputs":[],"execution_count":669},{"cell_type":"code","source":"train_dataset = []\nfor image_file in os.listdir(train_0_path):\n    img = tensor(torchvision.io.read_image(train_0_path + image_file), dtype = torch.float)\n    image_corner = img[:, :2, :2]\n    if(torch.mean(image_corner, dim = (1,2))[1] > 0):\n        train_dataset.append((img, torch.tensor([1,0], dtype = torch.float)))\n        \nfor image_file in os.listdir(train_1_path):\n    img = tensor(torchvision.io.read_image(train_1_path + image_file), dtype = torch.float)\n    image_corner = img[:, :2, :2]\n    if(torch.mean(image_corner, dim = (1,2))[0] > 0):\n        train_dataset.append((img, torch.tensor([0,1], dtype = torch.float)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T19:02:32.661346Z","iopub.execute_input":"2024-11-17T19:02:32.662073Z","iopub.status.idle":"2024-11-17T19:02:34.446214Z","shell.execute_reply.started":"2024-11-17T19:02:32.662031Z","shell.execute_reply":"2024-11-17T19:02:34.445402Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/1880147879.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  img = tensor(torchvision.io.read_image(train_0_path + image_file), dtype = torch.float)\n/tmp/ipykernel_30/1880147879.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  img = tensor(torchvision.io.read_image(train_1_path + image_file), dtype = torch.float)\n","output_type":"stream"}],"execution_count":670},{"cell_type":"code","source":"test_0_path = '/kaggle/input/colored-mnist-dataset/colorized-MNIST-master/testing/0/'\ntest_1_path = '/kaggle/input/colored-mnist-dataset/colorized-MNIST-master/testing/1/'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T19:02:34.447767Z","iopub.execute_input":"2024-11-17T19:02:34.448096Z","iopub.status.idle":"2024-11-17T19:02:34.452580Z","shell.execute_reply.started":"2024-11-17T19:02:34.448061Z","shell.execute_reply":"2024-11-17T19:02:34.451653Z"}},"outputs":[],"execution_count":671},{"cell_type":"code","source":"test_dataset = []\nfor image_file in os.listdir(test_0_path):\n    img = tensor(torchvision.io.read_image(test_0_path + image_file), dtype = torch.float)\n    image_corner = img[:, :2, :2]\n    if(torch.mean(image_corner, dim = (1,2))[0] > 0):\n        test_dataset.append((img, torch.tensor([1,0], dtype = torch.float)))\n\nfor image_file in os.listdir(test_1_path):\n    img = tensor(torchvision.io.read_image(test_1_path + image_file), dtype = torch.float)\n    image_corner = img[:, :2, :2]\n    if(torch.mean(image_corner, dim = (1,2))[1] > 0):\n        test_dataset.append((img, torch.tensor([0,1], dtype = torch.float)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T19:02:34.453838Z","iopub.execute_input":"2024-11-17T19:02:34.454218Z","iopub.status.idle":"2024-11-17T19:02:36.436686Z","shell.execute_reply.started":"2024-11-17T19:02:34.454174Z","shell.execute_reply":"2024-11-17T19:02:36.435831Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/3809860643.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  img = tensor(torchvision.io.read_image(test_0_path + image_file), dtype = torch.float)\n/tmp/ipykernel_30/3809860643.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  img = tensor(torchvision.io.read_image(test_1_path + image_file), dtype = torch.float)\n","output_type":"stream"}],"execution_count":672},{"cell_type":"code","source":"valid_dataset = train_dataset[int((len(train_dataset)) * 0.9):]\ntrain_dataset = train_dataset[:int((len(train_dataset)) * 0.9)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T19:02:36.438626Z","iopub.execute_input":"2024-11-17T19:02:36.438984Z","iopub.status.idle":"2024-11-17T19:02:36.444169Z","shell.execute_reply.started":"2024-11-17T19:02:36.438949Z","shell.execute_reply":"2024-11-17T19:02:36.443227Z"}},"outputs":[],"execution_count":673},{"cell_type":"code","source":"sample_image = train_dataset[0][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T19:02:36.445325Z","iopub.execute_input":"2024-11-17T19:02:36.445669Z","iopub.status.idle":"2024-11-17T19:02:36.452717Z","shell.execute_reply.started":"2024-11-17T19:02:36.445614Z","shell.execute_reply":"2024-11-17T19:02:36.451894Z"}},"outputs":[],"execution_count":674},{"cell_type":"code","source":"model = CustomCNN(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T19:02:36.453784Z","iopub.execute_input":"2024-11-17T19:02:36.454094Z","iopub.status.idle":"2024-11-17T19:02:36.462261Z","shell.execute_reply.started":"2024-11-17T19:02:36.454062Z","shell.execute_reply":"2024-11-17T19:02:36.461585Z"}},"outputs":[],"execution_count":675},{"cell_type":"code","source":"model.eval()\ns1, s2, s3, s4, s5, main_out = model(sample_image.unsqueeze(0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T19:02:36.463436Z","iopub.execute_input":"2024-11-17T19:02:36.463794Z","iopub.status.idle":"2024-11-17T19:02:36.471242Z","shell.execute_reply.started":"2024-11-17T19:02:36.463752Z","shell.execute_reply":"2024-11-17T19:02:36.470306Z"}},"outputs":[],"execution_count":676},{"cell_type":"code","source":"shape1 = s1.shape[1:]\nshape2 = s2.shape[1:] \nshape3 = s3.shape[1:] \nshape4 = s4.shape[1:] \nshape5 = s5.shape[1:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T19:02:36.472344Z","iopub.execute_input":"2024-11-17T19:02:36.472667Z","iopub.status.idle":"2024-11-17T19:02:36.482172Z","shell.execute_reply.started":"2024-11-17T19:02:36.472630Z","shell.execute_reply":"2024-11-17T19:02:36.481445Z"}},"outputs":[],"execution_count":677},{"cell_type":"code","source":"model_sieve = CustomCNN_sieve(shape1, shape2, shape3, shape4, shape5, 2).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T19:02:36.483351Z","iopub.execute_input":"2024-11-17T19:02:36.483726Z","iopub.status.idle":"2024-11-17T19:02:36.494237Z","shell.execute_reply.started":"2024-11-17T19:02:36.483681Z","shell.execute_reply":"2024-11-17T19:02:36.493446Z"}},"outputs":[],"execution_count":678},{"cell_type":"code","source":"weights = tensor([0.5, 0.3, 0.1, 0.07, 0.03], device = device, requires_grad = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T19:02:36.891978Z","iopub.execute_input":"2024-11-17T19:02:36.892688Z","iopub.status.idle":"2024-11-17T19:02:36.897413Z","shell.execute_reply.started":"2024-11-17T19:02:36.892642Z","shell.execute_reply":"2024-11-17T19:02:36.896446Z"}},"outputs":[],"execution_count":679},{"cell_type":"code","source":"dataloader = DataLoader(train_dataset, batch_size = 32, shuffle = True)\nopt_core = torch.optim.Adam(model_sieve.parameters(), lr = 1e-3)\nopt_sieve = torch.optim.Adam(\n    list(model_sieve.sieve1.parameters()) +\n    list(model_sieve.sieve2.parameters()) +\n    list(model_sieve.sieve3.parameters()) +\n    list(model_sieve.sieve4.parameters()) +\n    list(model_sieve.sieve5.parameters()),\n    lr=1e-3\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T19:01:59.178494Z","iopub.execute_input":"2024-11-17T19:01:59.179261Z","iopub.status.idle":"2024-11-17T19:01:59.186758Z","shell.execute_reply.started":"2024-11-17T19:01:59.179218Z","shell.execute_reply":"2024-11-17T19:01:59.185698Z"}},"outputs":[],"execution_count":662},{"cell_type":"code","source":"total_iterations = 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T19:01:59.515276Z","iopub.execute_input":"2024-11-17T19:01:59.516367Z","iopub.status.idle":"2024-11-17T19:01:59.520143Z","shell.execute_reply.started":"2024-11-17T19:01:59.516321Z","shell.execute_reply":"2024-11-17T19:01:59.519200Z"}},"outputs":[],"execution_count":663},{"cell_type":"code","source":"def get_accuracy(test_dataset, model):\n    model.eval()\n    correct = 0\n    for i in range(len(test_dataset)):\n        image = test_dataset[i][0].to(device).unsqueeze(0)\n        label = test_dataset[i][1].to(device)\n        \n        _, _, _ ,_,_, main_pred = model(image)\n        correct += torch.argmax(main_pred) == torch.argmax(test_dataset[i][1])\n        \n        image = image.to('cpu')\n        label = label.to('cpu')\n    return correct.item()/len(test_dataset) * 100 ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T19:01:59.920645Z","iopub.execute_input":"2024-11-17T19:01:59.921020Z","iopub.status.idle":"2024-11-17T19:01:59.927751Z","shell.execute_reply.started":"2024-11-17T19:01:59.920984Z","shell.execute_reply":"2024-11-17T19:01:59.926832Z"}},"outputs":[],"execution_count":664},{"cell_type":"code","source":"model.train()\nfor i in range(total_iterations):\n    training(model_sieve, dataloader, opt_core, opt_sieve, 2, 1, 10)\n    # forgetting(model_sieve, weights, dataloader, opt_core, 2, 1, 5)\n    print(f\"The iteration is {i} and the validation set accuracy is {get_accuracy(valid_dataset, model_sieve)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T19:02:00.264945Z","iopub.execute_input":"2024-11-17T19:02:00.265322Z","iopub.status.idle":"2024-11-17T19:02:01.687640Z","shell.execute_reply.started":"2024-11-17T19:02:00.265284Z","shell.execute_reply":"2024-11-17T19:02:01.686777Z"}},"outputs":[{"name":"stderr","text":" 20%|██        | 2/10 [00:00<00:01,  7.38it/s]","output_type":"stream"},{"name":"stdout","text":"The epoch is 1, the main loss is 0.7827012538909912 and the sieve loss is 12.432634970721077\nThe epoch is 2, the main loss is 0.6345311263028313 and the sieve loss is 3.999729465035831\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [00:00<00:00,  7.46it/s]","output_type":"stream"},{"name":"stdout","text":"The epoch is 3, the main loss is 0.5803164839744568 and the sieve loss is 2.7727481056662167\nThe epoch is 4, the main loss is 0.48568326760740843 and the sieve loss is 2.6821666885824764\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [00:00<00:00,  7.47it/s]","output_type":"stream"},{"name":"stdout","text":"The epoch is 5, the main loss is 0.4695095875683953 and the sieve loss is 2.3131158772636864\nThe epoch is 6, the main loss is 0.46239835900418896 and the sieve loss is 1.9722502582213457\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [00:01<00:00,  7.49it/s]","output_type":"stream"},{"name":"stdout","text":"The epoch is 7, the main loss is 0.45882128091419444 and the sieve loss is 1.5602403528550093\nThe epoch is 8, the main loss is 0.4535786807537079 and the sieve loss is 1.2505750726251041\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:01<00:00,  7.47it/s]","output_type":"stream"},{"name":"stdout","text":"The epoch is 9, the main loss is 0.4475888662478503 and the sieve loss is 1.0116958863594954\nThe epoch is 10, the main loss is 0.44402795679428997 and the sieve loss is 0.8520476677838493\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"The iteration is 0 and the validation set accuracy is 100.0\n","output_type":"stream"}],"execution_count":665},{"cell_type":"code","source":"get_accuracy(train_dataset, model_sieve)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T19:02:03.172541Z","iopub.execute_input":"2024-11-17T19:02:03.173538Z","iopub.status.idle":"2024-11-17T19:02:03.833633Z","shell.execute_reply.started":"2024-11-17T19:02:03.173484Z","shell.execute_reply":"2024-11-17T19:02:03.832696Z"}},"outputs":[{"execution_count":666,"output_type":"execute_result","data":{"text/plain":"100.0"},"metadata":{}}],"execution_count":666},{"cell_type":"code","source":"get_accuracy(test_dataset, model_sieve)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T19:02:04.864810Z","iopub.execute_input":"2024-11-17T19:02:04.865585Z","iopub.status.idle":"2024-11-17T19:02:05.727098Z","shell.execute_reply.started":"2024-11-17T19:02:04.865546Z","shell.execute_reply":"2024-11-17T19:02:05.726172Z"}},"outputs":[{"execution_count":667,"output_type":"execute_result","data":{"text/plain":"9.256661991584853"},"metadata":{}}],"execution_count":667},{"cell_type":"code","source":"image_tensor = next(train_iter)[0]\nplt.imshow(image_tensor.permute(1,2,0))\nimage_tensor = image_tensor[:, :5, :5]\nprint(image_tensor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T17:49:30.925799Z","iopub.status.idle":"2024-11-17T17:49:30.926143Z","shell.execute_reply.started":"2024-11-17T17:49:30.925971Z","shell.execute_reply":"2024-11-17T17:49:30.925989Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}